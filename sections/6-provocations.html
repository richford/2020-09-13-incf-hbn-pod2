<section data-menu-title="Provocations">
  <h1>Questions and Provocations</h1>
</section>

<section>
  <h2>The quality of what, exactly?</h2>
  <div class="row vspace">
    <div class="col-40">
      <img class="logo" src="./img/participant_with_cyst.gif" width="700" align="middle"
          alt="An HBN participant with an anatomical abnormality.">
    </div>
    <div class="col-60">
      <div class="fragment current-visible vspace">
        <h4>Question</h4>
        <ul>
          <li>What do we make of this participant?</li>
          <li>Obvious anatomical abnormality</li>
          <li>But very high DWI data quality:
            <ul>
              <li>High neighboring DWI correlation</li>
              <li>Low framewise displacement</li>
              <li>QC scores above 0.9</li>
            </ul>
          </li>
          <li>
            Should we include them in a study of normative brains?
            Probably not.
          </li>
          <li>But that decision is made on the basis of other criteria, not DWI data quality.</li>
        </ul>
      </div>
      <div class="fragment current-visible vspace">
        <h4>Lesson</h4>
        <ul>
          <li>QC scores are <u><b>exclusion criteria</b></u>, not inclusion criteria</li>
          <li>No single measurement is suitable as an inclusion criterion, <u><b>by itself</b></u></li>
          <li>
            Researchers should consult many different sources of information, e.g.,
            <ul>
              <li>Streamline counts</li>
              <li>T1w quality measures</li>
            </ul>
          </li>
        </ul>
        <h4 class="vspace">Provocation</h4>
        <ul>
          <li>What is the appropriate dimensionality of a quality assessment?</li>
          <li>What is the utility of single, scalar, whole-brain, domain-agnostic QC scores?</li>
        </ul>
      </div>
    </div>
  </div>
</section>

<section>
  <h2>When is a multi-tiered protocol appropriate?</h2>
  <div class="row vspace">
    <div class="two-col">
      <h4>Pros</h4>
      <ul>
        <li>Supplies enough data to CNN QC model</li>
        <div class="fragment tab">
          <p>
            But we can use less data hungry models.
            <br>
            But we can ask more of our expert raters.
          </p>
        </div>
        <li>Engages public in neuroimaging research</li>
        <div class="fragment tab">
          <p>Yes, but many of our community raters came from neuroscience labs.</p>
        </div>
      </ul>
    </div>
    <div class="two-col">
      <h4>Cons</h4>
      <ul>
        <li>Burdensome to collect</li>
        <div class="fragment tab">
          <p>For whom? This is a tradeoff between rater burden vs. study
          coordinator burden</p>
        </div>
        <li>Violates some data usage agreements (e.g. ABCD)</li>
        <div class="fragment tab">
          <p>But only for community raters. The high-volume raters can also have
          DUCs.</p>
        </div>
      </ul>
    </div>
  </div>
  <div class="fragment vspace">
    <h4>Lesson</h4>
    <ul>
      <li>
        Naively, multi-tiered rating is appropriate when the extra data
        generated is worth the administrative burden of adding another tier.
      </li>
      <li>"More is different," even with data.
        <br>
        <cite>~ Anderson, P. W. (1972). Science, 177(4047), 393-396.</cite>
      </li>
      <li>The Swipes framework reduces the burden of adding another tier.</li>
    </ul>
  </div>
</section>
